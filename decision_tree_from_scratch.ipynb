{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Decision Trees from Scratch\n", "\n# Decision Trees from Scratch\n\n```python\nfrom collections import Counter\nimport numpy as np\n\nclass DecisionTree:\n    def __init__(self, max_depth=None):\n        self.max_depth = max_depth\n        self.tree = None\n\n    def fit(self, X, y):\n        self.tree = self._build_tree(X, y)\n\n    def _build_tree(self, X, y, depth=0):\n        if len(set(y)) == 1:\n            return y[0]  # If all labels are the same, return the label\n        \n        if self.max_depth and depth >= self.max_depth:\n            return Counter(y).most_common(1)[0][0]  # Majority class\n\n        best_split = self._find_best_split(X, y)\n        left_tree = self._build_tree(*best_split['left'], depth + 1)\n        right_tree = self._build_tree(*best_split['right'], depth + 1)\n        \n        return {'feature': best_split['feature'], 'threshold': best_split['threshold'],\n                'left': left_tree, 'right': right_tree}\n\n    def _find_best_split(self, X, y):\n        best_split = {}\n        min_gini = float('inf')\n        \n        for feature in range(X.shape[1]):\n            thresholds = set(X[:, feature])\n            for threshold in thresholds:\n                left_mask = X[:, feature] <= threshold\n                right_mask = ~left_mask\n                left_y = y[left_mask]\n                right_y = y[right_mask]\n                \n                gini = self._calculate_gini(left_y, right_y)\n                if gini < min_gini:\n                    min_gini = gini\n                    best_split = {'feature': feature, 'threshold': threshold, 'left': (X[left_mask], left_y), 'right': (X[right_mask], right_y)}\n        \n        return best_split\n\n    def _calculate_gini(self, left_y, right_y):\n        left_size = len(left_y)\n        right_size = len(right_y)\n        total_size = left_size + right_size\n        \n        left_gini = 1 - sum((np.sum(left_y == label) / left_size) ** 2 for label in set(left_y))\n        right_gini = 1 - sum((np.sum(right_y == label) / right_size) ** 2 for label in set(right_y))\n        \n        return (left_size / total_size) * left_gini + (right_size / total_size) * right_gini\n\n    def predict(self, X):\n        return np.array([self._predict_one(x, self.tree) for x in X])\n\n    def _predict_one(self, x, tree):\n        if isinstance(tree, dict):\n            if x[tree['feature']] <= tree['threshold']:\n                return self._predict_one(x, tree['left'])\n            else:\n                return self._predict_one(x, tree['right'])\n        else:\n            return tree\n```\n\nYou can use this class to create a decision tree model and train it on any dataset, such as the Iris dataset, as follows:\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load dataset\ndata = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n\n# Initialize Decision Tree model\nmodel = DecisionTree(max_depth=5)\n\n# Fit the model\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy}\")\n```\n\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "version": "3.10.6"}}, "nbformat": 4, "nbformat_minor": 5}